{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40866e8a",
   "metadata": {},
   "source": [
    "# <center> Wrangle Report \n",
    "<center> By Ezekiel Okato\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08f3231",
   "metadata": {},
   "source": [
    "<a id=\"#intro\"></a>\n",
    "## Introduction\n",
    "Data wrangling and in particular data cleaning, forms the bulk of data analysis since this process is as repetitive as need be to ensure the data presented is accurate, precise, and answers the intended questions fully. For this project (**Analyzing Tweets from WeRateDogs (@dogrates)**), several processes were taken to satisfy the objectives of the project i.e. Data Wrangling and Exploratory Data Analysis (EDA) and Data Visualization\n",
    "\n",
    "This report covers the Wrangling phase of the data from `WeRateDogs` which involves gathering, assessing, and cleaning data. The data used for this project was *gathered* using 3 methods i.e.: manually downloading available data, performing a Request to call the URL that hosts the data, and querying Twitter API for additional data. The data was then *assessed* for quality and tidiness issues. Finally, the data was *cleaned* and respective datasets were *merged* and *stored* pending *EDA and Data Visualization*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78896cce",
   "metadata": {},
   "source": [
    "<a id=\"#gathering\"></a>\n",
    "## Gathering Data\n",
    "For the project, 3 datasets were required in order to successfully accomplish the analysis.\n",
    "\n",
    "* Dataset 1 - Enhanced Twitter Archive\n",
    "\n",
    "This dataset was provided by Udacity to be downloaded manually which contains the basic data for 5,000+ Tweets. Udacity enhanced this original dataset by extracting dog ratings, dog names, and dog stage from each Tweet's text data. The original dataset was filtered to produce 2,356 rows of data which include only the Tweets that appear to mention dog ratings during enhancement.\n",
    "\n",
    "* Dataset 2 - Image Predictions\n",
    "\n",
    "Udacity provided the **image_predictions.tsv** which is hosted on Udacity's servers and was downloaded programmatically using the Requests library and the following URL: https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv\n",
    "\n",
    "* Dataset 3 - Additional Tweet Data\n",
    "\n",
    "The retweet and favourite counts of each tweet which were omitted during the process of enhancing the Twitter archive were gathered by querying Twitter's API with Python's Tweepy library. This JSON-formatted data was dumped to a .txt file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f48e799",
   "metadata": {},
   "source": [
    "<a id=\"#assessing\"></a>\n",
    "## Assessing Data\n",
    "\n",
    "The three datasets gathered were assessed for quality issues which deal with the content of the data and tidiness issues which affect the structure of the data. Only necessary observations of issues pertaining to cleaning of data were documented.\n",
    "\n",
    "During assessment, a copy of each dataset was created and assessed. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96176b2",
   "metadata": {},
   "source": [
    "<a id=\"#cleaning\"></a>\n",
    "## Cleaning, Merging and Storing Data\n",
    "\n",
    "The issues identified in Assessing Data were addressed in the *define-code-test* framework.\n",
    "\n",
    "* Define: details an actionable plan for necessary cleaning operations.\n",
    "* Code: the plan is put into into codes and the cleaning operation is done programmatically.\n",
    "* Test: verifies that the issue is resolved.\n",
    "\n",
    "After cleaning, the datasets were merged and then stored as a separate file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1da262",
   "metadata": {},
   "source": [
    "<a id=\"#conclusion\"></a>\n",
    "## Conclusion\n",
    "This report covered  wrangling data on Tweets from WeRateDogs (@dogrates). Data wrangling comprised of:\n",
    "* Gathering Data\n",
    "\n",
    "Three datasets were obtained. One was obtained manually and the other two were obtained programmatically.\n",
    "\n",
    "* Assessing Data\n",
    "\n",
    "The datasets were assessed for quality and tidiness issues. However, due to the volume of the datasets, only the necessary (those relevant to answering questions) issues that required cleaning were identified.\n",
    "\n",
    "* Cleaning Data\n",
    "\n",
    "The define-code-test framework was applied to clean all the identified issues. The datasets were the merged and stored ina file awaiting EDA and data visualization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c5c92a",
   "metadata": {},
   "source": [
    "## References\n",
    "* https://pandas.pydata.org/pandas-docs/stable/reference/index.html\n",
    "* https://matplotlib.org/stable/api/pyplot_summary.html\n",
    "* https://seaborn.pydata.org/generated/seaborn.countplot.html#seaborn.countplot\n",
    "* https://www.geeksforgeeks.org/python-seaborn-tutorial/?ref=lbp\n",
    "* https://www.geeksforgeeks.org/matplotlib-tutorial/?ref=lbp\n",
    "* https://www.jstatsoft.org/article/view/v059i10\n",
    "* https://stackoverflow.com/questions/44703945/pandas-trouble-stripping-html-tags-from-dataframe-column\n",
    "* https://stackoverflow.com/questions/51519101/simultaneously-melt-multiple-columns-in-python-pandas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
